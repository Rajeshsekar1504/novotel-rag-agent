# ğŸ“¡ NovaTel RAG Agent

Production-grade Retrieval-Augmented Generation (RAG) system for telecom customer support.
Built using FastAPI, LangChain, LangGraph, OpenAI embeddings, ChromaDB, and React.

This system ingests telecom knowledge base documents (.docx), generates embeddings, stores them in ChromaDB, and serves grounded answers via an AI agent.

---

# ğŸš€ Features

## RAG System

* DOCX knowledge base ingestion
* Incremental indexing using file hashing
* Automatic detection of new/changed documents
* Removal of deleted document embeddings
* Persistent Chroma vector database
* Deterministic chunk IDs (idempotent ingestion)

## Backend

* FastAPI production API
* LangGraph agent orchestration
* Modular architecture
* Structured logging

## Frontend

* React + Vite chat interface
* Real-time responses
* Source attribution

## DevOps

* Conda environment
* Shell automation scripts
* Logging system
* Docker support

---

# ğŸ“‚ Project Structure

```
novotel-rag-agent/
â”‚
â”œâ”€â”€ .github/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ rag/
â”‚   â”œâ”€â”€ agent/
â”‚   â”œâ”€â”€ logs/
â”‚   â”œâ”€â”€ main.py
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ chroma_db/              # Vector database
â”œâ”€â”€ documents/              # Knowledge base DOCX files
â”œâ”€â”€ frontend/               # React frontend
â”œâ”€â”€ infra/                  # Infrastructure configs
â”œâ”€â”€ scripts/                # Automation scripts
â”‚
â”œâ”€â”€ novotel-rag/            # Conda environment
â”‚
â”œâ”€â”€ .env
â”œâ”€â”€ hash_registry.json
â””â”€â”€ README.md
```

---

# âš™ï¸ Environment Setup

You already created a conda environment inside project:

```
novotel-rag/
```

Activate it:

```
conda activate D:/novotel-rag-agent/novotel-rag
```

Verify:

```
python --version
```

---

# ğŸ“¦ Install Dependencies

Backend:

```
pip install -r backend/requirements.txt
```

Frontend:

```
cd frontend
npm install
cd ..
```

---

# ğŸ” Environment Variables

Create `.env`

```
OPENAI_API_KEY=your_key_here
ANONYMIZED_TELEMETRY=False
```

---

# ğŸ“¥ Knowledge Base Ingestion

Place DOCX files in:

```
documents/
```

Run ingestion:

```
./scripts/ingest.sh
```

This will:

â€¢ detect new files
â€¢ generate embeddings
â€¢ update vector database

---

# â–¶ Start Backend

```
./scripts/start_backend.sh
```

Runs at:

```
http://localhost:8000
```

---

# â–¶ Start Frontend

```
./scripts/start_frontend.sh
```

Runs at:

```
http://localhost:5173
```

---

# ğŸ”„ Restart System

```
./scripts/restart.sh
```

---

# ğŸ›‘ Stop System

```
./scripts/stop.sh
```

---

# ğŸ§ª Test Vector Database

```
python backend/rag/test.py
```

Shows total indexed chunks.

---

# ğŸ“Š Logs

Located at:

```
backend/logs/
```

Includes:

```
rag_system.log
backend.pid
frontend.pid
```

---

# ğŸ§  System Architecture

```
DOCX files
   â†“
Ingestion pipeline
   â†“
OpenAI embeddings
   â†“
Chroma vector database
   â†“
Retriever
   â†“
LangGraph agent
   â†“
FastAPI backend
   â†“
React frontend
```

---

# âš¡ Performance

Typical ingestion:

```
40 chunks â†’ 30â€“90 seconds
```

Query response:

```
< 1 second
```

---

# ğŸ³ Docker (optional)

Build:

```
docker build -t novotel-rag .
```

Run:

```
docker compose up
```

---

# ğŸ“Œ Production Features Implemented

Incremental indexing
File hashing
Persistent vector DB
Deterministic chunk IDs
Script automation
Logging
Frontend + Backend separation

---

# ğŸ‘¨â€ğŸ’» Author

NovaTel RAG Agent
Production-grade telecom support AI system
